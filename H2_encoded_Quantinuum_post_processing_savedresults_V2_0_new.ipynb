{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meenagowrishankar/code_demo_qed/blob/main/H2_encoded_Quantinuum_post_processing_savedresults_V2_0_new.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "musical-conclusion",
      "metadata": {
        "id": "musical-conclusion"
      },
      "source": [
        "Program for post-processing results from running a 6 qubit, [[4,2,2]] hydrogen vqe with post-selection of the counts based on ancilla 1 = 0, logical state parity, and based on both ancilla 1 = 0 and logical state parity, and separating expectation values by value of ancilla 2 measurement. <br>\n",
        "**Bit order LSB for Quantinuum Emulator: $|q_nq_{n-1}...q_0\\rangle$, regardless of order of measurement in circuit, results are reordered in the output file in the order mentioned above.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "after-logistics",
      "metadata": {
        "id": "after-logistics"
      },
      "outputs": [],
      "source": [
        "# import xacc\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import math\n",
        "import numpy as np\n",
        "import pickle\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "L-b9jNkk93EJ"
      },
      "id": "L-b9jNkk93EJ",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "e21d8abc",
      "metadata": {
        "id": "e21d8abc"
      },
      "source": [
        "**Functions for post-processing data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "romance-gibraltar",
      "metadata": {
        "id": "romance-gibraltar"
      },
      "outputs": [],
      "source": [
        "# Separate the parallel circuit counts into individual circuit counts\n",
        "\n",
        "def sep_counts(counts:dict) -> dict:\n",
        "    '''\n",
        "    Returns tuples of tuples of bitstring and measurements of each circuit\n",
        "    within a parallel execution of three circuits.\n",
        "    Takes a dictionary, counts, with bitstrings as keys and\n",
        "    returns list of tuples with six bit bitstrings as keys with corresponding\n",
        "    values of the origial key in the original counts dictionary. Tuples used because\n",
        "    the resulting six bit bitstrings are non-unique.\n",
        "\n",
        "        Parameters:\n",
        "            counts (dict) : counts for all measured bitstrings\n",
        "            MSB (bool): determines the bit order (defaults to True (MSB))\n",
        "    '''\n",
        "\n",
        "    all_counts = dict(counts)\n",
        "\n",
        "    for key in all_counts.keys():\n",
        "#         print(\"key: \", all_counts)\n",
        "        list1 = tuple((k[:6],v) for k,v in all_counts.items())\n",
        "        list2 = tuple((k[12:],v) for k,v in all_counts.items())\n",
        "        list3 = tuple((k[6:12],v) for k,v in all_counts.items())\n",
        "\n",
        "#     print(list1,list2,list3)\n",
        "\n",
        "    return list1, list2, list3\n",
        "\n",
        "\n",
        "def combine_counts(counts:dict)->dict:\n",
        "    '''\n",
        "    Returns a measurement counts dictionary by combining the counts of three circuits run in parallel.\n",
        "    Parameters: dictionary with the counts of bitstring for three circuits run in parallel.\n",
        "    Counts is a tuple of tuples. Each tuple within tuple consists of a pair, with first element of the\n",
        "    tuple being the two bit bitstring and the second element, the associated measurement value of the bitstring.\n",
        "    Returns dictionary with keys as the two bit bitstring, and as value, the total measurement counts of the corresponding\n",
        "    two bit bistring obtained from the sum of the second element of each tuple that has as its\n",
        "    first element the bitstring key of the dictionary.\n",
        "    '''\n",
        "\n",
        "    # separate the whole bitstring into bitstrngs of each circuit and assign the correspinding value\n",
        "    # of the whole bitstring to each of the split bitstrings\n",
        "    counts1, counts2, counts3 = sep_counts(counts)\n",
        "\n",
        "    # dictionary to split counts for non-unique bitstrings\n",
        "    counts_dict1 = {}\n",
        "    counts_dict2 = {}\n",
        "    counts_dict3 = {}\n",
        "\n",
        "    # Create dictionary for each key in each of the two dictionaries\n",
        "    for key, value in counts2:\n",
        "#         print(key)\n",
        "        counts_dict2[key] = 0\n",
        "\n",
        "    for key, value in counts1:\n",
        "        counts_dict1[key] = 0\n",
        "\n",
        "    for key, value in counts3:\n",
        "        counts_dict3[key] = 0\n",
        "\n",
        "    # Add counts for each non-unique bitstring in each of the two dictionaries\n",
        "    for key, value in counts2:\n",
        "        if key in counts_dict2.keys():\n",
        "            counts_dict2[key] += value\n",
        "    for key, value in counts1:\n",
        "        if key in counts_dict1.keys():\n",
        "            counts_dict1[key]+=value\n",
        "\n",
        "    for key, value in counts3:\n",
        "        if key in counts_dict3.keys():\n",
        "            counts_dict3[key]+=value\n",
        "\n",
        "#     counts_dict1, counts_dict2\n",
        "\n",
        "    counts_dict = {}\n",
        "    for key, value in counts_dict1.items():\n",
        "        if key in counts_dict.keys():\n",
        "            counts_dict[key] += counts_dict1[key]\n",
        "\n",
        "        else:\n",
        "            counts_dict[key] = counts_dict1[key]\n",
        "\n",
        "    for key, value in counts_dict2.items():\n",
        "        if key in counts_dict.keys():\n",
        "            counts_dict[key] += counts_dict2[key]\n",
        "\n",
        "        else:\n",
        "            counts_dict[key] = counts_dict2[key]\n",
        "\n",
        "    for key, value in counts_dict3.items():\n",
        "        if key in counts_dict.keys():\n",
        "            counts_dict[key] += counts_dict3[key]\n",
        "\n",
        "        else:\n",
        "            counts_dict[key] = counts_dict3[key]\n",
        "\n",
        "    return counts_dict\n",
        "\n",
        "def counts_list(counts:list, point, pauli):\n",
        "    '''\n",
        "    Takes list of dictionaries with six bit bitsrings and measurement counts for a Pauli term in the Hamiltonian,\n",
        "    each dictionary is created from the corresponding file with results of a single parallel execution of\n",
        "    six qubit circuits for a certain number of shots. Returns list of dictionaries for the specific Pauli\n",
        "    term from each to be combined using meta_combine function.\n",
        "    '''\n",
        "    counts_list = []\n",
        "    original_list = []\n",
        "    for count in counts:\n",
        "        counts_list.append(count[point][pauli]['MeasurementCounts'])\n",
        "    return counts_list\n",
        "\n",
        "def meta_combine(counts:list):\n",
        "    '''\n",
        "    Takes a list of dictionaries associated with a single Pauli term from the Hamiltonian\n",
        "    within counts with multiple dictionaries of measurements and counts created from each file\n",
        "    containing the results of each execution of parallel six-qubit circuits.\n",
        "    Returns a single combined dictionary of bitstrings and measurement counts for use in calculating\n",
        "    expectation values.\n",
        "    '''\n",
        "    comb_counts_dict = {}\n",
        "    combine_counts = Counter()\n",
        "    for count in counts:\n",
        "        combine_counts+=Counter(count)\n",
        "        comb_counts_dict = dict(combine_counts)\n",
        "\n",
        "    return dict(comb_counts_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "binding-olympus",
      "metadata": {
        "id": "binding-olympus"
      },
      "outputs": [],
      "source": [
        "# check if empty before combining counts\n",
        "def check_and_combine(counts:dict)->dict:\n",
        "    '''\n",
        "    Check if dictionary is empty and then proceed with combining counts if not empty.\n",
        "    '''\n",
        "    if not counts:\n",
        "        return {}\n",
        "    else:\n",
        "        return combine_counts(counts)\n",
        "#     new_counts = combine_counts(counts)\n",
        "#     return new_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "formal-ground",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "formal-ground",
        "outputId": "c9bcd763-ca54-463f-e89a-595281530289"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'001100': 12, '223322': 10, '443344': 1, '445566': 7}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# test for combine_counts, check_and_combine\n",
        "\n",
        "newstuff = {\"001100223322445566\":4, \"223322223322445566\":3, '001100001100001100':2, '443344001100001100': 1}\n",
        "# newstuff = {\"001100\":4, \"223322\":3, '001100':2, '443344': 1}\n",
        "# for key in newstuff.keys():\n",
        "#     print(key[12:])\n",
        "combine_counts(newstuff)\n",
        "# check_and_combine(newstuff)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "corrected-delay",
      "metadata": {
        "id": "corrected-delay"
      },
      "outputs": [],
      "source": [
        "# post selects based on the value of ancilla 1. Discards the counts with ancilla 1 = \"1\".\n",
        "\n",
        "### q_6 is ancilla_1\n",
        "\n",
        "def post_select_on_ancila_1(counts: dict, MSB: bool = True) -> dict:\n",
        "\n",
        "    '''\n",
        "    Returns a dictionary with counts post-selected on ancilla 0.\n",
        "\n",
        "        Parameters:\n",
        "            counts (dict): Counts for all measured bitstrings.\n",
        "            MSB (bool): Determines the bit order (Defaults to True (MSB)).\n",
        "\n",
        "        Returns:\n",
        "            post_selected_counts (dict): Post-selected counts.\n",
        "    '''\n",
        "\n",
        "    post_selected_counts = dict(counts)\n",
        "    for key in counts.keys():\n",
        "        # if MSB order, then q0 is the first\n",
        "        if key[0] == \"1\" and MSB:\n",
        "            del post_selected_counts[key]\n",
        "        # if LSB, then q0 is the last\n",
        "        if key[-1] == \"1\" and not MSB:\n",
        "            del post_selected_counts[key]\n",
        "\n",
        "    return post_selected_counts\n",
        "\n",
        "def post_select_codespace(counts: dict, MSB: bool = True)-> dict:\n",
        "\n",
        "    '''\n",
        "    Returns a dictionary with counts post-selected for bitstrings outside codespace for\n",
        "    Pauli terms except for X2X3.\n",
        "\n",
        "        Parameters:\n",
        "            counts (dict): Ancilla 1 corrected counts for all measured bitstrings.\n",
        "            MSB (bool): Determines the bit order (Defaults to True (MSB)).\n",
        "\n",
        "        Returns:\n",
        "            post_selected_codespace (dict): Post-selected bitstrings.\n",
        "    '''\n",
        "    # codespace defined by the bitstrings in the four physical basis states of the encoding\n",
        "    codespace = ['0000', '1111', '1001', '0110', '1010', '0101', '0011', '1100']\n",
        "    post_selected_codespace = dict(counts)\n",
        "    for key in counts.keys():\n",
        "        # if MSB order, then q0 is the first\n",
        "        if key[2:] not in codespace and MSB:\n",
        "            del post_selected_codespace[key]\n",
        "        # if LSB, then q0 is the last\n",
        "        if key[1:5] not in codespace and not MSB:\n",
        "            del post_selected_codespace[key]\n",
        "\n",
        "\n",
        "    return post_selected_codespace\n",
        "\n",
        "# returns the parity of the bit string that is passed in to calculate\n",
        "# the correct expectation value without considering the measure statements\n",
        "# as additional Pauli terms as done right now by xacc/qpus.\n",
        "\n",
        "def has_even_parity(bitstring: int) -> bool:\n",
        "\n",
        "    '''\n",
        "    Checks if bitstring is an even decimal number.\n",
        "\n",
        "        Parameters:\n",
        "            bitstring (int): bitstring in binary representation.\n",
        "\n",
        "        Returns:\n",
        "            parity (bool): Returns True if even and False if odd.\n",
        "    '''\n",
        "\n",
        "    count = 0\n",
        "    b = 1\n",
        "    parity = True\n",
        "    for i in range(32):\n",
        "        if (bitstring & (b << i)): count += 1\n",
        "    if (count % 2): parity = False\n",
        "    return parity\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "prerequisite-shopping",
      "metadata": {
        "id": "prerequisite-shopping"
      },
      "outputs": [],
      "source": [
        "# Calculate expectation value for each pauli term in the Hamiltonian\n",
        "\n",
        "def PauliEnergies(theta:float, counts:dict, MSB: bool = True):\n",
        "\n",
        "    '''\n",
        "    Takes as input each individual theta value and dictionary\n",
        "    with \"correcCounts\" from the post_select_on_ancila_1 function\n",
        "    for that theta\n",
        "    Returns the dictionary counts with Pauli expectation values\n",
        "    for ancilla 2 = 0 and ancilla 2 = 1 and separate counts for a2 = 0 and 1.\n",
        "    '''\n",
        "    PauliExpVal = {}\n",
        "#     PauliExpVal[theta] = {}\n",
        "    for key, pauli in counts.items():\n",
        "#         print(key)\n",
        "#         print(PauliExpVal)\n",
        "        # for calculating expectation values as a sum for ancilla 2 = 0 and ancilla 2 = 1\n",
        "        exp_value_theta = 0.0\n",
        "        exp_val = 0.0\n",
        "\n",
        "        # Separate the post-selected measurement counts into two dictionaries depending on the value of ancilla 2\n",
        "        a_0 = {}\n",
        "        a_1 = {}\n",
        "        a0 = {}\n",
        "        a1 = {}\n",
        "\n",
        "        for bitstring in pauli['correctCounts'].keys():\n",
        "            if bitstring[5] == '0' and MSB:\n",
        "\n",
        "                a_0[bitstring] = pauli['correctCounts'][bitstring]\n",
        "\n",
        "            if bitstring[5] == '1' and MSB:\n",
        "\n",
        "                a_1[bitstring] = pauli['correctCounts'][bitstring]\n",
        "\n",
        "            if bitstring[0] == '0' and not MSB:\n",
        "\n",
        "                a_0[bitstring] = pauli['correctCounts'][bitstring]\n",
        "\n",
        "            if bitstring[0] == '1' and not MSB:\n",
        "\n",
        "                a_1[bitstring] = pauli['correctCounts'][bitstring]\n",
        "\n",
        "\n",
        "        # for calculating expectation values as a sum for ancilla 2 = 0 and ancilla 2 = 1\n",
        "        exp_value_theta = 0.0\n",
        "        exp_val = 0.0\n",
        "\n",
        "        # Find the parity of the bitstring in each dictionary by excluding the bits not part of the Pauli\n",
        "        # strings in the Hamiltonian (q0 and q5) and assign the correct sign to the expectation values based\n",
        "        # on the parity for LSB bit order\n",
        "\n",
        "        for bitstr in a_0.keys():\n",
        "            prob = a_0[bitstr]/sum(a_0.values())\n",
        "            if key == 'z2z3' or key == 'x2x3':\n",
        "                is_even = has_even_parity(int(bitstr[2:4], 2))\n",
        "                if(not is_even):\n",
        "                    prob = -prob\n",
        "#                 print(\"prob_a1: \",key, prob)\n",
        "                exp_val += prob\n",
        "            if key == 'z1z2':\n",
        "                is_even = has_even_parity(int(bitstr[3:5], 2))\n",
        "#                 is_even = has_even_parity(int(bitstr[0:2], 2))\n",
        "                if(not is_even):\n",
        "                    prob = -prob\n",
        "        #                 print(\"prob_a1: \",prob)\n",
        "                exp_val += prob\n",
        "            if key == 'z1z3':\n",
        "                is_even = has_even_parity(int(bitstr[4]+bitstr[2], 2))\n",
        "#                 is_even = has_even_parity(int(bitstr[0]+bitstr[2], 2))\n",
        "                if(not is_even):\n",
        "                    prob = -prob\n",
        "        #                 print(\"prob_a1: \",prob)\n",
        "                exp_val += prob\n",
        "\n",
        "\n",
        "        for bitstr in a_1.keys():\n",
        "            prob = a_1[bitstr]/sum(a_1.values())\n",
        "            if key == 'z2z3' or key == 'x2x3':\n",
        "                is_even = has_even_parity(int(bitstr[2:4], 2))\n",
        "                if(not is_even):\n",
        "                    prob = -prob\n",
        "        #                 print(\"prob_a1: \",prob)\n",
        "                exp_value_theta += prob\n",
        "            if key == 'z1z2':\n",
        "                is_even = has_even_parity(int(bitstr[3:5], 2))\n",
        "#                 is_even = has_even_parity(int(bitstr[0:2], 2))\n",
        "                if(not is_even):\n",
        "                    prob = -prob\n",
        "        #                 print(\"prob_a1: \",prob)\n",
        "                exp_value_theta += prob\n",
        "            if key == 'z1z3':\n",
        "                is_even = has_even_parity(int(bitstr[4]+bitstr[2], 2))\n",
        "#                 is_even = has_even_parity(int(bitstr[0]+bitstr[2], 2))\n",
        "                if(not is_even):\n",
        "                    prob = -prob\n",
        "        #                 print(\"prob_a1: \",prob)\n",
        "                exp_value_theta += prob\n",
        "\n",
        "\n",
        "\n",
        "        coefficient = counts[key]['coefficient']\n",
        "#         print('coeff ',coefficient)\n",
        "\n",
        "        # Total for calculating probability of success\n",
        "        total_counts = sum(counts[key]['MeasurementCounts'].values())\n",
        "        total_a2_0 = sum(a_0.values())\n",
        "        total_a2_1 = sum(a_1.values())\n",
        "        counts[key]['a2_0 exp-val'] = exp_val\n",
        "        counts[key]['a2_1 exp-val'] = exp_value_theta\n",
        "        counts[key]['a2_0 counts'] = a_0\n",
        "        counts[key]['a2_1 counts'] = a_1\n",
        "        # Probability of success p0 for each a_2 measurement\n",
        "        if key == 'I':\n",
        "            counts[key]['p0_a20'] = 0.0\n",
        "            counts[key]['p0_a21'] = 0.0\n",
        "        else:\n",
        "            counts[key]['p0_a20'] = total_a2_0/total_counts\n",
        "            counts[key]['p0_a21'] = total_a2_1/total_counts\n",
        "    PauliExpVal[theta] = counts\n",
        "\n",
        "\n",
        "    return counts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "attempted-output",
      "metadata": {
        "id": "attempted-output"
      },
      "outputs": [],
      "source": [
        "# Calculates total energy of the Hamiltonian by summing up the expecation values of each Pauli term after\n",
        "# multiplying with their respective coefficients\n",
        "def totalEnergy_a20(theta:float, paulis_ev:dict):\n",
        "\n",
        "    '''\n",
        "    Takes as input theta value and associated pauli expectation values from the dictionary output of PauliEnergies function\n",
        "    Calculates the total energy of the Hamiltonian by summing up the individual Pauli term expectation values\n",
        "    for ancilla 2 = 0, after multiplying each value by their respective cofficients\n",
        "\n",
        "    Returns total energy\n",
        "    '''\n",
        "    energy = paulis_ev[theta]['I']['coefficient']\n",
        "    for key, pauli_dict in paulis_ev[theta].items():\n",
        "        # compute energies\n",
        "\n",
        "#         print('energyini ', energy)\n",
        "        energy += paulis_ev[theta][key]['coefficient'] * paulis_ev[theta][key]['a2_0 exp-val']\n",
        "#         print('energy', energy)\n",
        "    return energy\n",
        "\n",
        "def totalEnergy_a21(theta:float, paulis_ev:dict):\n",
        "\n",
        "    '''\n",
        "    Takes as input theta value and associated pauli expectation values from the dictionary output of PauliEnergies function\n",
        "    Calculates the total energy of the Hamiltonian by summing up the individual Pauli term expectation values\n",
        "    for ancilla 2 = 1, after multiplying each value by their respective cofficients\n",
        "\n",
        "    Returns total energy\n",
        "    '''\n",
        "\n",
        "    energy_rot = paulis_ev[theta]['I']['coefficient']\n",
        "    for key, pauli_dict in paulis_ev[theta].items():\n",
        "        # compute energies\n",
        "\n",
        "#         print('energyini ', energy_rot)\n",
        "\n",
        "        energy_rot += paulis_ev[theta][key]['coefficient'] * paulis_ev[theta][key]['a2_1 exp-val']\n",
        "#         print('energy', energy_rot)\n",
        "    return energy_rot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "binding-superior",
      "metadata": {
        "id": "binding-superior"
      },
      "outputs": [],
      "source": [
        "def OptEnergyOptParams(energy_dict:dict):\n",
        "    '''\n",
        "    Takes as input the dictionary output of energies from the totalEnergy_a20 or totalEnergy_a21 function\n",
        "    and outputs the minimum energy and the associated parameter\n",
        "    '''\n",
        "    opt_energy = min(energy_dict.values())\n",
        "    opt_params = min(energy_dict, key=energy_dict.get)\n",
        "    return{'opt-energy': opt_energy,\n",
        "           'opt-param': opt_params}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "enclosed-trash",
      "metadata": {
        "id": "enclosed-trash"
      },
      "outputs": [],
      "source": [
        "## find variance and standard error of the mean for energy estimate\n",
        "\n",
        "def SW_Var_a20(results:dict):\n",
        "    '''\n",
        "    Takes dictionary with data for optimal parameter, for\n",
        "    ancilla 2 = 0 or 1 and finds variance of the energy using\n",
        "    the Satterthwaite correction to account for\n",
        "    different sample sizes for X and Z pauli operators.\n",
        "    Returns Standard Error of the Mean using counts for ancilla 2 = 0\n",
        "    '''\n",
        "    varCS_sum = 0.0\n",
        "    var = 0.0\n",
        "    for pauli in results.keys():\n",
        "#         print(results[depol]['a2_0']['data'][pauli]['coefficient'])\n",
        "        if pauli != 'I':\n",
        "#             print('coeff ', results[pauli]['coefficient']**2,\n",
        "#                   'ev ', results[pauli]['a2_0 exp-val']**2,\n",
        "#                 'diff ev ', 1-(results[pauli]['a2_0 exp-val']**2),\n",
        "#                 'sum ', sum(results[pauli]['a2_0 counts'].values()))\n",
        "            varCS_sum += (results[pauli]['coefficient']**2)\\\n",
        "                             *(1-(results[pauli]['a2_0 exp-val']**2))\\\n",
        "                            /sum(results[pauli]['a2_0 counts'].values())\n",
        "            var += (results[pauli]['coefficient']**2)\\\n",
        "                             *(1-(results[pauli]['a2_0 exp-val']**2))\n",
        "    varCS = np.sqrt(varCS_sum)\n",
        "\n",
        "    return varCS, var\n",
        "\n",
        "def SW_Var_a21(results:dict):\n",
        "    '''\n",
        "    Takes dictionary with data for optimal parameter and optimized energy, for\n",
        "    ancilla 2 = 0 or 1 and finds variance of the energy using\n",
        "    the Satterthwaite correction to account for\n",
        "    different sample sizes for X and Z pauli operators.\n",
        "    Returns Standard Error of the Mean using counts for ancilla 2 = 1\n",
        "    '''\n",
        "    varCS_sum = 0.0\n",
        "    var = 0.0\n",
        "    for pauli in results.keys():\n",
        "#         print(results[depol]['a2_0']['data'][pauli]['coefficient'])\n",
        "        if pauli != 'I':\n",
        "#             print('coeff ', results[pauli]['coefficient']**2,\n",
        "#                   'ev ', results[pauli]['a2_1 exp-val']**2,\n",
        "#                 'diff ev ', 1-(results[pauli]['a2_1 exp-val']**2),\n",
        "#                 'sum ', sum(results[pauli]['a2_1 counts'].values()))\n",
        "            varCS_sum += (results[pauli]['coefficient']**2)\\\n",
        "                             *(1-(results[pauli]['a2_1 exp-val']**2))\\\n",
        "                            /sum(results[pauli]['a2_1 counts'].values())\n",
        "            var += (results[pauli]['coefficient']**2)\\\n",
        "                             *(1-(results[pauli]['a2_1 exp-val']**2))\n",
        "\n",
        "    varCS = np.sqrt(varCS_sum)\n",
        "\n",
        "    return varCS, var\n",
        "\n",
        "\n",
        "\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### unzip file\n",
        "# !unzip /content/encoded_counts_noiseless_1.zip\n",
        "!unzip /content/encoded_counts_noisy_1.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHVAeTaO-bXk",
        "outputId": "528af1f7-c2a4-4a0a-ca3a-1d3abdfaef9c"
      },
      "id": "cHVAeTaO-bXk",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/encoded_counts_noisy_1.zip\n",
            "   creating: encoded_counts_noisy_1/\n",
            "  inflating: __MACOSX/._encoded_counts_noisy_1  \n",
            "  inflating: encoded_counts_noisy_1/H1-1E_VQEH2_Enc_3parallelCircs_noisy_10000shots_run1_part1.pkl  \n",
            "  inflating: __MACOSX/encoded_counts_noisy_1/._H1-1E_VQEH2_Enc_3parallelCircs_noisy_10000shots_run1_part1.pkl  \n",
            "  inflating: encoded_counts_noisy_1/._H1-1E_VQEH2_Enc_3parallelCircs_noisy_10000shots_run1_part1.pkl  \n",
            "  inflating: encoded_counts_noisy_1/H1-1E_VQEH2_Enc_3parallelCircs_noisy_10000shots_run1_part2.pkl  \n",
            "  inflating: __MACOSX/encoded_counts_noisy_1/._H1-1E_VQEH2_Enc_3parallelCircs_noisy_10000shots_run1_part2.pkl  \n",
            "  inflating: encoded_counts_noisy_1/._H1-1E_VQEH2_Enc_3parallelCircs_noisy_10000shots_run1_part2.pkl  \n",
            "  inflating: encoded_counts_noisy_1/H1-1E_VQEH2_Enc_3parallelCircs_noisy_10000shots_run1_part3.pkl  \n",
            "  inflating: __MACOSX/encoded_counts_noisy_1/._H1-1E_VQEH2_Enc_3parallelCircs_noisy_10000shots_run1_part3.pkl  \n",
            "  inflating: encoded_counts_noisy_1/._H1-1E_VQEH2_Enc_3parallelCircs_noisy_10000shots_run1_part3.pkl  \n",
            "  inflating: encoded_counts_noisy_1/H1-1E_VQEH2_Enc_3parallelCircs_noisy_10000shots_run1_part4.pkl  \n",
            "  inflating: __MACOSX/encoded_counts_noisy_1/._H1-1E_VQEH2_Enc_3parallelCircs_noisy_10000shots_run1_part4.pkl  \n",
            "  inflating: encoded_counts_noisy_1/._H1-1E_VQEH2_Enc_3parallelCircs_noisy_10000shots_run1_part4.pkl  \n",
            "  inflating: encoded_counts_noisy_1/H1-1E_VQEH2_Enc_3parallelCircs_noisy_10000shots_run1_part5.pkl  \n",
            "  inflating: __MACOSX/encoded_counts_noisy_1/._H1-1E_VQEH2_Enc_3parallelCircs_noisy_10000shots_run1_part5.pkl  \n",
            "  inflating: encoded_counts_noisy_1/._H1-1E_VQEH2_Enc_3parallelCircs_noisy_10000shots_run1_part5.pkl  \n",
            "  inflating: encoded_counts_noisy_1/H1-1E_VQEH2_Enc_3parallelCircs_noisy_10000shots_run1_part6.pkl  \n",
            "  inflating: __MACOSX/encoded_counts_noisy_1/._H1-1E_VQEH2_Enc_3parallelCircs_noisy_10000shots_run1_part6.pkl  \n",
            "  inflating: encoded_counts_noisy_1/._H1-1E_VQEH2_Enc_3parallelCircs_noisy_10000shots_run1_part6.pkl  \n",
            "  inflating: encoded_counts_noisy_1/H1-1E_VQEH2_Enc_3parallelCircs_noisy_2667shots_run1_part7.pkl  \n",
            "  inflating: __MACOSX/encoded_counts_noisy_1/._H1-1E_VQEH2_Enc_3parallelCircs_noisy_2667shots_run1_part7.pkl  \n",
            "  inflating: encoded_counts_noisy_1/._H1-1E_VQEH2_Enc_3parallelCircs_noisy_2667shots_run1_part7.pkl  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### delete extra files generated during unzip\n",
        "!find /content/encoded_counts_noiseless_1 -type f -name '._*' -delete\n",
        "!find /content/encoded_counts_noisy_1 -type f -name '._*' -delete"
      ],
      "metadata": {
        "id": "C3EMCqHa-pRe"
      },
      "id": "C3EMCqHa-pRe",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "discrete-contemporary",
      "metadata": {
        "id": "discrete-contemporary"
      },
      "source": [
        "**Workflow begins here**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "wooden-bundle",
      "metadata": {
        "id": "wooden-bundle"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "\n",
        "# Function to create list of results with the result from each file as elements\n",
        "def read_pickle_files_to_list(directory):\n",
        "    all_results = []\n",
        "\n",
        "    # Iterate over all files in the directory\n",
        "    for filename in os.listdir(directory):\n",
        "        file_path = os.path.join(directory, filename)\n",
        "\n",
        "        # Check if it is a file and if it ends with .pkl (or other pickle extension)\n",
        "        if os.path.isfile(file_path) and file_path.endswith('.pkl'):\n",
        "            with open(file_path, 'rb') as file:\n",
        "                results = pickle.load(file)\n",
        "                all_results.append(results)\n",
        "\n",
        "    return all_results\n",
        "\n",
        "# Specify the directory containing the pickle files\n",
        "# directory_path = '/content/encoded_counts_noiseless_1'\n",
        "directory_path = '/content/encoded_counts_noisy_1'\n",
        "\n",
        "# Read pickle files and get the list of contents\n",
        "all_results = read_pickle_files_to_list(directory_path)\n",
        "\n",
        "# Print the contents of each pickle file\n",
        "# for index, content in enumerate(all_results):\n",
        "#     print(f\"Content of pickle file {index + 1}:\\n{content}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "perceived-european",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "perceived-european",
        "outputId": "efa651c6-fe2c-4247-cdcb-895e04faea3a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "len(all_results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "surgical-admission",
      "metadata": {
        "id": "surgical-admission"
      },
      "outputs": [],
      "source": [
        "# function to combine all counts within a file after splitting\n",
        "# combined bitstring to get bitstrings for each circuit in a parallel run\n",
        "def get_total_counts_per_file(splitcounts, points):\n",
        "    for point in points:\n",
        "        for key, terms in splitcounts[point].items():\n",
        "            splitcounts[point][key]['MeasurementCounts'] = check_and_combine(terms['OriginalCounts'])\n",
        "\n",
        "    return splitcounts\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "changing-ground",
      "metadata": {
        "id": "changing-ground"
      },
      "outputs": [],
      "source": [
        "total_ech_file = []\n",
        "# points_test = [-0.400606, -0.358437, -0.316268, -0.274099, -0.23193 , -0.189761, -0.147592, -0.105423, -0.063254, -0.021085]\n",
        "points_test = [-0.22967]\n",
        "# points_test = [-0.23193]\n",
        "for result in all_results:\n",
        "    combined_results = {}\n",
        "    combined_results = get_total_counts_per_file(result, points_test)\n",
        "    total_ech_file.append(combined_results)\n",
        "# get_total_counts_per_file(all_results[0], points_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "equal-correspondence",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "equal-correspondence",
        "outputId": "dcc6665a-4605-4be3-f1e5-70d4b798ba08"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "len(total_ech_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "monthly-outdoors",
      "metadata": {
        "id": "monthly-outdoors"
      },
      "outputs": [],
      "source": [
        "# Create a results_test dictionary from an element of total_ech_file to\n",
        "# retain structure of dictionary for post-selection steps\n",
        "results_test = total_ech_file[0].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "enhanced-night",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enhanced-night",
        "outputId": "66bd61a8-97d0-4645-c0d8-d099fc688d86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "False\n",
            "1\n",
            "False\n",
            "2\n",
            "True\n",
            "3\n",
            "True\n",
            "4\n",
            "True\n",
            "5\n",
            "True\n",
            "6\n"
          ]
        }
      ],
      "source": [
        "# test that sums of measurement counts are same or different for the one file with <10000 shots\n",
        "for i in range(len(total_ech_file)):\n",
        "    print(i)\n",
        "    if i < len(total_ech_file)-1:\n",
        "        print(sum(total_ech_file[i][-0.22967]['z1z2']['MeasurementCounts'].values())==sum(total_ech_file[i+1][-0.22967]['z1z2']['MeasurementCounts'].values()))\n",
        "\n",
        "# len(total_ech_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "headed-incidence",
      "metadata": {
        "id": "headed-incidence"
      },
      "outputs": [],
      "source": [
        "# Counts list creates a lits of bitstring:counts dictionaries for each point and each pauli from all the files\n",
        "for point in points_test:\n",
        "    for pauli in ['I', 'z1z2', 'z1z3','z2z3', 'x2x3']:\n",
        "\n",
        "         results_test[point][pauli]['counts_list'] = counts_list(total_ech_file, point, pauli)\n",
        "\n",
        "# Combines list of counts dictionaries for each point and each pauli\n",
        "for point in points_test:\n",
        "    for pauli in ['I', 'z1z2', 'z1z3', 'z2z3', 'x2x3']:\n",
        "        results_test[point][pauli]['MeasurementCounts'] = meta_combine(results_test[point][pauli]['counts_list'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "danish-vehicle",
      "metadata": {
        "id": "danish-vehicle"
      },
      "outputs": [],
      "source": [
        "## Save combined results in a file\n",
        "# pickle.dump(results_test, open('VQEenc_Counts_Quantinuum_combined188001shots_h1-1E.pkl', 'wb'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0edfd32",
      "metadata": {
        "id": "f0edfd32"
      },
      "source": [
        "**Workflow: Post-selection for [[4,2,2]] code**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "rotary-string",
      "metadata": {
        "id": "rotary-string"
      },
      "outputs": [],
      "source": [
        "##### Workflow continued\n",
        "\n",
        "## NO POST-SELECTION\n",
        "\n",
        "shot = 188001\n",
        "final_data = {'a2_0':{}, 'a2_1':{}}\n",
        "# collect the expectation values of all the pauli terms in this dictionary\n",
        "pauli_expval_test = {}\n",
        "# collect values of total energy by value of theta in these dictionaries based on ancilla 2 value = 0 or 1\n",
        "thetaEVa20_test = {}\n",
        "thetaEVa21_test = {}\n",
        "\n",
        "# collect values of minimum energy and correspinding optimal parameter for each dictionary containing total\n",
        "# energy separated by ancilla 2 values\n",
        "a20_noisy_exp_val = {}\n",
        "a21_noisy_exp_val = {}\n",
        "#loop over points and generate the dictionary with parameters and associated measurement counts\n",
        "\n",
        "for point in points_test:\n",
        "\n",
        "    # loop over keys and dictionaries of the pauli terms for each parameter and get correct counts\n",
        "    # by discarding measurements with a1 = 1\n",
        "    for key, terms in results_test[point].items():\n",
        "\n",
        "        results_test[point][key]['correctCounts'] = results_test[point][key]['MeasurementCounts']\n",
        "\n",
        "    # find the expectation values for each Pauli term for each parameter separated by the value of ancilla 2\n",
        "    pauli_expval_test[point] = PauliEnergies(point, results_test[point], False)\n",
        "\n",
        "    # find total energy energy by summing exp-val of all Pauli terms for each parameter but separated by ancilla value\n",
        "    thetaEVa20_test[point] = totalEnergy_a20(point, pauli_expval_test)\n",
        "    thetaEVa21_test[point] = totalEnergy_a21(point, pauli_expval_test)\n",
        "\n",
        "#     with open(f'422EncodingVQE_a20_{depol}noise_{shot}shots_CSQtuum_Compare_thetaVsE.txt', 'w') as f:\n",
        "#         f.write(json.dumps(thetaEVa20_test))\n",
        "\n",
        "#     with open(f'422EncodingVQE_a21_{depol}noise_{shot}shots_CSQtuum_Compare_thetaVsE.txt', 'w') as f:\n",
        "#         f.write(json.dumps(thetaEVa21_test))\n",
        "# find minimum energy and optimal parameter for each ancilla 2 value by depolarizing parameter\n",
        "results_a20_test = OptEnergyOptParams(thetaEVa20_test)\n",
        "results_a21_test = OptEnergyOptParams(thetaEVa21_test)\n",
        "\n",
        "# get minimum energy and optimal parameter for each depolarizing parameter\n",
        "a20_noisy_exp_val = results_a20_test\n",
        "a21_noisy_exp_val = results_a21_test\n",
        "#     print(results_a20_test)\n",
        "# calculate SEM\n",
        "a20_sem, a20_var = SW_Var_a20(results_test[results_a20_test['opt-param']])\n",
        "a21_sem, a21_var = SW_Var_a21(results_test[results_a21_test['opt-param']])\n",
        "\n",
        "# collect results associated with optimal paramter\n",
        "final_data['a2_0']['exp-val'] = results_a20_test['opt-energy']\n",
        "final_data['a2_0']['data'] = results_test[results_a20_test['opt-param']]\n",
        "final_data['a2_1']['exp-val'] = results_a21_test['opt-energy']\n",
        "final_data['a2_1']['data'] = results_test[results_a21_test['opt-param']]\n",
        "final_data['a2_0']['var'] = a20_var\n",
        "final_data['a2_1']['var'] = a21_var\n",
        "final_data['a2_0']['sem'] = a20_sem\n",
        "final_data['a2_1']['sem'] = a21_sem\n",
        "a20_noisy_exp_val['var'] = final_data['a2_0']['var']\n",
        "a21_noisy_exp_val['var'] = final_data['a2_1']['var']\n",
        "a20_noisy_exp_val['sem'] = final_data['a2_0']['sem']\n",
        "a21_noisy_exp_val['sem'] = final_data['a2_1']['sem']\n",
        "a20_noisy_exp_val['p0_z'] = final_data['a2_0']['data']['z1z2']['p0_a20']\n",
        "a20_noisy_exp_val['p0_x'] = final_data['a2_0']['data']['x2x3']['p0_a20']\n",
        "a21_noisy_exp_val['p0_z'] = final_data['a2_1']['data']['z1z2']['p0_a21']\n",
        "a21_noisy_exp_val['p0_x'] = final_data['a2_1']['data']['x2x3']['p0_a21']\n",
        "final_data['a2_0']['all-theta'] = thetaEVa20_test\n",
        "final_data['a2_1']['all-theta'] = thetaEVa21_test\n",
        "\n",
        "# ### SAVE data\n",
        "# import json\n",
        "\n",
        "# import pickle\n",
        "\n",
        "# pickle.dump(final_data, open(f'VQEenc_results_noisy_{shot}shots_noPS_LSB_H1-1E.pkl', 'wb'))\n",
        "\n",
        "# with open(f'422EncodingVQE_a20_noisy_{shot}shots_noPS_LSB_H1-1E.txt', 'w') as f:\n",
        "#     f.write(json.dumps(a20_noisy_exp_val))\n",
        "\n",
        "# with open(f'422EncodingVQE_a21_noisy_{shot}shots_noPS_LSB_H1-1E.txt', 'w') as f:\n",
        "#     f.write(json.dumps(a21_noisy_exp_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "private-status",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "private-status",
        "outputId": "5bdd9ac6-5524-447d-fd37-4407bb44cfea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'opt-energy': -1.1182957344535067,\n",
              " 'opt-param': -0.22967,\n",
              " 'var': 0.06053630806897241,\n",
              " 'sem': 0.0008009981756164023,\n",
              " 'p0_z': 0.5022473284716571,\n",
              " 'p0_x': 0.5015239280642124}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "\n",
        "a20_noisy_exp_val\n",
        "# thetaEVa20_test\n",
        "# final_data['a2_0']\n",
        "# results_a20_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "moving-prevention",
      "metadata": {
        "id": "moving-prevention"
      },
      "outputs": [],
      "source": [
        "## POST-SELECTION BY ANCILLA A1=0\n",
        "\n",
        "shot = 188001\n",
        "final_data = {'a2_0':{}, 'a2_1':{}}\n",
        "# collect the expectation values of all the pauli terms in this dictionary\n",
        "pauli_expval_test = {}\n",
        "# collect values of total energy by value of theta in these dictionaries based on ancilla 2 value = 0 or 1\n",
        "thetaEVa20_test = {}\n",
        "thetaEVa21_test = {}\n",
        "\n",
        "# collect values of minimum energy and correspinding optimal parameter for each dictionary containing total\n",
        "# energy separated by ancilla 2 values\n",
        "a20_noisy_exp_val = {}\n",
        "a21_noisy_exp_val = {}\n",
        "\n",
        "\n",
        "#loop over every parameter to find expectation values for each\n",
        "\n",
        "for point in points_test:\n",
        "\n",
        "    # loop over keys and dictionaries of the pauli terms for each parameter and get correct counts\n",
        "    # by discarding measurements with a1 = 1\n",
        "    for key, terms in results_test[point].items():\n",
        "\n",
        "        # remove counts with ancilla a1 = 0\n",
        "        results_test[point][key]['correctCounts'] = post_select_on_ancila_1(terms['MeasurementCounts'], False)\n",
        "#         results_test[point][key]['correctCounts'] = terms['MeasurementCounts']\n",
        "\n",
        "    # find the expectation values for each Pauli term for each parameter separated by the value of ancilla 2\n",
        "    pauli_expval_test[point] = PauliEnergies(point, results_test[point], False)\n",
        "\n",
        "    # find total energy energy by summing exp-val of all Pauli terms for each parameter but separated by ancilla value\n",
        "    thetaEVa20_test[point] = totalEnergy_a20(point, pauli_expval_test)\n",
        "    thetaEVa21_test[point] = totalEnergy_a21(point, pauli_expval_test)\n",
        "\n",
        "#     with open(f'422EncodingVQE_a20_{depol}noise_{shot}shots_CSQtuum_Compare_thetaVsE.txt', 'w') as f:\n",
        "#         f.write(json.dumps(thetaEVa20_test))\n",
        "\n",
        "#     with open(f'422EncodingVQE_a21_{depol}noise_{shot}shots_CSQtuum_Compare_thetaVsE.txt', 'w') as f:\n",
        "#         f.write(json.dumps(thetaEVa21_test))\n",
        "# find minimum energy and optimal parameter for each ancilla 2 value by depolarizing parameter\n",
        "results_a20_test = OptEnergyOptParams(thetaEVa20_test)\n",
        "results_a21_test = OptEnergyOptParams(thetaEVa21_test)\n",
        "\n",
        "# get minimum energy and optimal parameter for each depolarizing parameter\n",
        "a20_noisy_exp_val = results_a20_test\n",
        "a21_noisy_exp_val = results_a21_test\n",
        "#     print(results_a20_test)\n",
        "# calculate SEM\n",
        "a20_sem, a20_var = SW_Var_a20(results_test[results_a20_test['opt-param']])\n",
        "a21_sem, a21_var = SW_Var_a21(results_test[results_a21_test['opt-param']])\n",
        "\n",
        "# collect results associated with optimal paramter\n",
        "final_data['a2_0']['exp-val'] = results_a20_test['opt-energy']\n",
        "final_data['a2_0']['data'] = results_test[results_a20_test['opt-param']]\n",
        "final_data['a2_1']['exp-val'] = results_a21_test['opt-energy']\n",
        "final_data['a2_1']['data'] = results_test[results_a21_test['opt-param']]\n",
        "final_data['a2_0']['var'] = a20_var\n",
        "final_data['a2_1']['var'] = a21_var\n",
        "final_data['a2_0']['sem'] = a20_sem\n",
        "final_data['a2_1']['sem'] = a21_sem\n",
        "a20_noisy_exp_val['var'] = final_data['a2_0']['var']\n",
        "a21_noisy_exp_val['var'] = final_data['a2_1']['var']\n",
        "a20_noisy_exp_val['sem'] = final_data['a2_0']['sem']\n",
        "a21_noisy_exp_val['sem'] = final_data['a2_1']['sem']\n",
        "a20_noisy_exp_val['p0_z'] = final_data['a2_0']['data']['z1z2']['p0_a20']\n",
        "a20_noisy_exp_val['p0_x'] = final_data['a2_0']['data']['x2x3']['p0_a20']\n",
        "a21_noisy_exp_val['p0_z'] = final_data['a2_1']['data']['z1z2']['p0_a21']\n",
        "a21_noisy_exp_val['p0_x'] = final_data['a2_1']['data']['x2x3']['p0_a21']\n",
        "final_data['a2_0']['all-theta'] = thetaEVa20_test\n",
        "final_data['a2_1']['all-theta'] = thetaEVa21_test\n",
        "\n",
        "\n",
        "### SAVE data\n",
        "\n",
        "# import json\n",
        "\n",
        "# import pickle\n",
        "\n",
        "# pickle.dump(final_data, open(f'VQEenc_results_noisy_{shot}shots_PSA_LSB_H1-1E.pkl', 'wb'))\n",
        "\n",
        "# with open(f'422EncodingVQE_a20_noisy_{shot}shots_PSA_LSB_H1-1E.txt', 'w') as f:\n",
        "#     f.write(json.dumps(a20_noisy_exp_val))\n",
        "\n",
        "# with open(f'422EncodingVQE_a21_noisy_{shot}shots_PSA_LSB_H1-1E.txt', 'w') as f:\n",
        "#     f.write(json.dumps(a21_noisy_exp_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "defined-blond",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "defined-blond",
        "outputId": "b2c80e1c-e6f8-4295-d1ef-944ee827e7bf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'opt-energy': -1.1203647393920662,\n",
              " 'opt-param': -0.22967,\n",
              " 'var': 0.05898636066274143,\n",
              " 'sem': 0.0007927892502720783,\n",
              " 'p0_z': 0.49968351232174296,\n",
              " 'p0_x': 0.49877926181243715}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "a20_noisy_exp_val\n",
        "# final_data['a2_0']['data']['z1z2']['correctCounts']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "owned-garden",
      "metadata": {
        "id": "owned-garden"
      },
      "outputs": [],
      "source": [
        "## POST-SELECTION BY PARITY\n",
        "\n",
        "shot = 188001\n",
        "final_data = {'a2_0':{}, 'a2_1':{}}\n",
        "# collect the expectation values of all the pauli terms in this dictionary\n",
        "pauli_expval_test = {}\n",
        "# collect values of total energy by value of theta in these dictionaries based on ancilla 2 value = 0 or 1\n",
        "thetaEVa20_test = {}\n",
        "thetaEVa21_test = {}\n",
        "\n",
        "# collect values of minimum energy and correspinding optimal parameter for each dictionary containing total\n",
        "# energy separated by ancilla 2 values\n",
        "a20_noisy_exp_val = {}\n",
        "a21_noisy_exp_val = {}\n",
        "\n",
        "#loop over points and generate the dictionary with parameters and associated measurement counts\n",
        "\n",
        "for point in points_test:\n",
        "\n",
        "    # loop over keys and dictionaries of the pauli terms for each parameter and get correct counts\n",
        "    # by discarding measurements with a1 = 1\n",
        "    for key, terms in results_test[point].items():\n",
        "\n",
        "        # For parity only post-selection, uncomment this and comment out above\n",
        "        results_test[point][key]['correctCounts'] = post_select_codespace(results_test[point][key]['MeasurementCounts'], False)\n",
        "\n",
        "    # find the expectation values for each Pauli term for each parameter separated by the value of ancilla 2\n",
        "    pauli_expval_test[point] = PauliEnergies(point, results_test[point], False)\n",
        "\n",
        "    # find total energy energy by summing exp-val of all Pauli terms for each parameter but separated by ancilla value\n",
        "    thetaEVa20_test[point] = totalEnergy_a20(point, pauli_expval_test)\n",
        "    thetaEVa21_test[point] = totalEnergy_a21(point, pauli_expval_test)\n",
        "\n",
        "#     with open(f'422EncodingVQE_a20_{depol}noise_{shot}shots_CSQtuum_Compare_thetaVsE.txt', 'w') as f:\n",
        "#         f.write(json.dumps(thetaEVa20_test))\n",
        "\n",
        "#     with open(f'422EncodingVQE_a21_{depol}noise_{shot}shots_CSQtuum_Compare_thetaVsE.txt', 'w') as f:\n",
        "#         f.write(json.dumps(thetaEVa21_test))\n",
        "# find minimum energy and optimal parameter for each ancilla 2 value by depolarizing parameter\n",
        "results_a20_test = OptEnergyOptParams(thetaEVa20_test)\n",
        "results_a21_test = OptEnergyOptParams(thetaEVa21_test)\n",
        "\n",
        "# get minimum energy and optimal parameter for each depolarizing parameter\n",
        "a20_noisy_exp_val = results_a20_test\n",
        "a21_noisy_exp_val = results_a21_test\n",
        "#     print(results_a20_test)\n",
        "# calculate SEM\n",
        "a20_sem, a20_var = SW_Var_a20(results_test[results_a20_test['opt-param']])\n",
        "a21_sem, a21_var = SW_Var_a21(results_test[results_a21_test['opt-param']])\n",
        "\n",
        "# collect results associated with optimal paramter\n",
        "final_data['a2_0']['exp-val'] = results_a20_test['opt-energy']\n",
        "final_data['a2_0']['data'] = results_test[results_a20_test['opt-param']]\n",
        "final_data['a2_1']['exp-val'] = results_a21_test['opt-energy']\n",
        "final_data['a2_1']['data'] = results_test[results_a21_test['opt-param']]\n",
        "final_data['a2_0']['var'] = a20_var\n",
        "final_data['a2_1']['var'] = a21_var\n",
        "final_data['a2_0']['sem'] = a20_sem\n",
        "final_data['a2_1']['sem'] = a21_sem\n",
        "a20_noisy_exp_val['var'] = final_data['a2_0']['var']\n",
        "a21_noisy_exp_val['var'] = final_data['a2_1']['var']\n",
        "a20_noisy_exp_val['sem'] = final_data['a2_0']['sem']\n",
        "a21_noisy_exp_val['sem'] = final_data['a2_1']['sem']\n",
        "a20_noisy_exp_val['p0_z'] = final_data['a2_0']['data']['z1z2']['p0_a20']\n",
        "a20_noisy_exp_val['p0_x'] = final_data['a2_0']['data']['x2x3']['p0_a20']\n",
        "a21_noisy_exp_val['p0_z'] = final_data['a2_1']['data']['z1z2']['p0_a21']\n",
        "a21_noisy_exp_val['p0_x'] = final_data['a2_1']['data']['x2x3']['p0_a21']\n",
        "final_data['a2_0']['all-theta'] = thetaEVa20_test\n",
        "final_data['a2_1']['all-theta'] = thetaEVa21_test\n",
        "\n",
        "\n",
        "### SAVE data\n",
        "\n",
        "# import json\n",
        "\n",
        "# import pickle\n",
        "\n",
        "# pickle.dump(final_data, open(f'VQEenc_results_noisy_{shot}shots_PSP_LSB_H1-1E.pkl', 'wb'))\n",
        "\n",
        "# with open(f'422EncodingVQE_a20_noisy_{shot}shots_PSP_LSB_H1-1E.txt', 'w') as f:\n",
        "#     f.write(json.dumps(a20_noisy_exp_val))\n",
        "\n",
        "# with open(f'422EncodingVQE_a21_noisy_{shot}shots_PSP_LSB_H1-1E.txt', 'w') as f:\n",
        "#     f.write(json.dumps(a21_noisy_exp_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "representative-hampshire",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "representative-hampshire",
        "outputId": "940dd3b6-29f5-4e67-e9d4-0093793107b5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'opt-energy': -1.1288046439901662,\n",
              " 'opt-param': -0.22967,\n",
              " 'var': 0.05290760022857842,\n",
              " 'sem': 0.0007544292378186278,\n",
              " 'p0_z': 0.4953324716357892,\n",
              " 'p0_x': 0.4938431178557561}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "a20_noisy_exp_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "swedish-fairy",
      "metadata": {
        "id": "swedish-fairy"
      },
      "outputs": [],
      "source": [
        "## POST SELECTION BY COMBINED METHOD\n",
        "\n",
        "shot = 188001\n",
        "final_data = {'a2_0':{}, 'a2_1':{}}\n",
        "# collect the expectation values of all the pauli terms in this dictionary\n",
        "pauli_expval_test = {}\n",
        "# collect values of total energy by value of theta in these dictionaries based on ancilla 2 value = 0 or 1\n",
        "thetaEVa20_test = {}\n",
        "thetaEVa21_test = {}\n",
        "\n",
        "# collect values of minimum energy and correspinding optimal parameter for each dictionary containing total\n",
        "# energy separated by ancilla 2 values\n",
        "a20_noisy_exp_val = {}\n",
        "a21_noisy_exp_val = {}\n",
        "\n",
        "#loop over points and generate the dictionary with parameters and associated measurement counts\n",
        "\n",
        "for point in points_test:\n",
        "\n",
        "    # loop over keys and dictionaries of the pauli terms for each parameter and get correct counts\n",
        "    # by discarding measurements with a1 = 1\n",
        "    for key, terms in results_test[point].items():\n",
        "\n",
        "        # remove counts with ancilla a1 = 0\n",
        "        results_test[point][key]['correctCounts'] = post_select_on_ancila_1(terms['MeasurementCounts'], False)\n",
        "#             # remove counts with bitstrings not included in the codespace + ancilla a1=0\n",
        "        results_test[point][key]['correctCounts'] = post_select_codespace(results_test[point][key]['correctCounts'], False)\n",
        "\n",
        "    # find the expectation values for each Pauli term for each parameter separated by the value of ancilla 2\n",
        "    pauli_expval_test[point] = PauliEnergies(point, results_test[point], False)\n",
        "\n",
        "    # find total energy energy by summing exp-val of all Pauli terms for each parameter but separated by ancilla value\n",
        "    thetaEVa20_test[point] = totalEnergy_a20(point, pauli_expval_test)\n",
        "    thetaEVa21_test[point] = totalEnergy_a21(point, pauli_expval_test)\n",
        "\n",
        "#     with open(f'422EncodingVQE_a20_{depol}noise_{shot}shots_CSQtuum_Compare_thetaVsE.txt', 'w') as f:\n",
        "#         f.write(json.dumps(thetaEVa20_test))\n",
        "\n",
        "#     with open(f'422EncodingVQE_a21_{depol}noise_{shot}shots_CSQtuum_Compare_thetaVsE.txt', 'w') as f:\n",
        "#         f.write(json.dumps(thetaEVa21_test))\n",
        "# find minimum energy and optimal parameter for each ancilla 2 value by depolarizing parameter\n",
        "results_a20_test = OptEnergyOptParams(thetaEVa20_test)\n",
        "results_a21_test = OptEnergyOptParams(thetaEVa21_test)\n",
        "\n",
        "# get minimum energy and optimal parameter for each depolarizing parameter\n",
        "a20_noisy_exp_val = results_a20_test\n",
        "a21_noisy_exp_val = results_a21_test\n",
        "#     print(results_a20_test)\n",
        "# calculate SEM\n",
        "a20_sem, a20_var = SW_Var_a20(results_test[results_a20_test['opt-param']])\n",
        "a21_sem, a21_var = SW_Var_a21(results_test[results_a21_test['opt-param']])\n",
        "\n",
        "# collect results associated with optimal paramter\n",
        "final_data['a2_0']['exp-val'] = results_a20_test['opt-energy']\n",
        "final_data['a2_0']['data'] = results_test[results_a20_test['opt-param']]\n",
        "final_data['a2_1']['exp-val'] = results_a21_test['opt-energy']\n",
        "final_data['a2_1']['data'] = results_test[results_a21_test['opt-param']]\n",
        "final_data['a2_0']['var'] = a20_var\n",
        "final_data['a2_1']['var'] = a21_var\n",
        "final_data['a2_0']['sem'] = a20_sem\n",
        "final_data['a2_1']['sem'] = a21_sem\n",
        "a20_noisy_exp_val['var'] = final_data['a2_0']['var']\n",
        "a21_noisy_exp_val['var'] = final_data['a2_1']['var']\n",
        "a20_noisy_exp_val['sem'] = final_data['a2_0']['sem']\n",
        "a21_noisy_exp_val['sem'] = final_data['a2_1']['sem']\n",
        "a20_noisy_exp_val['p0_z'] = final_data['a2_0']['data']['z1z2']['p0_a20']\n",
        "a20_noisy_exp_val['p0_x'] = final_data['a2_0']['data']['x2x3']['p0_a20']\n",
        "a21_noisy_exp_val['p0_z'] = final_data['a2_1']['data']['z1z2']['p0_a21']\n",
        "a21_noisy_exp_val['p0_x'] = final_data['a2_1']['data']['x2x3']['p0_a21']\n",
        "final_data['a2_0']['all-theta'] = thetaEVa20_test\n",
        "final_data['a2_1']['all-theta'] = thetaEVa21_test\n",
        "\n",
        "### SAVE data\n",
        "\n",
        "# import json\n",
        "\n",
        "# import pickle\n",
        "\n",
        "# pickle.dump(final_data, open(f'VQEenc_results_noisy_{shot}shots_PSAP_LSB_H1-1E.pkl', 'wb'))\n",
        "\n",
        "# with open(f'422EncodingVQE_a20_noisy_{shot}shots_PSAP_LSB_H1-1E.txt', 'w') as f:\n",
        "#     f.write(json.dumps(a20_noisy_exp_val))\n",
        "\n",
        "# with open(f'422EncodingVQE_a21_noisy_{shot}shots_PSAP_LSB_H1-1E.txt', 'w') as f:\n",
        "#     f.write(json.dumps(a21_noisy_exp_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "sharing-reservation",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sharing-reservation",
        "outputId": "bf9a5585-2bb0-4d18-a7a2-38fef1b0de70"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'opt-energy': -1.129784831552889,\n",
              " 'opt-param': -0.22967,\n",
              " 'var': 0.052181350137215456,\n",
              " 'sem': 0.000750760204030219,\n",
              " 'p0_z': 0.4933324822740305,\n",
              " 'p0_x': 0.49184844761464036}"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "a20_noisy_exp_val"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U83qQV_k_72Z"
      },
      "id": "U83qQV_k_72Z",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}